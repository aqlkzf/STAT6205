{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Probabilistic Principal Component Analysis (PPCA) on Digits Dataset\n",
    "\n",
    "This code implements PPCA by two methods:\n",
    "1. ML solution using spectral decomposition.\n",
    "2. EM algorithm for PPCA.\n",
    "\n",
    "The data is loaded from the digits dataset in sklearn, and we perform dimensionality reduction and projection on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.linalg import eigh, inv\nfrom sklearn.datasets import load_digits\nfrom sklearn.manifold import TSNE\n# Set display configuration\n%config InlineBackend.figure_format = \"retina\"\nnp.set_printoptions(precision=4, suppress=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading\n",
    "Load the digits dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data      # Each sample is 64-dimensional (8x8 image)\n",
    "y = digits.target\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Unique labels:\", np.unique(y))\n",
    "\n",
    "Xtrain = X\n",
    "ytrain = y\n",
    "N, D = Xtrain.shape\n",
    "print(\"Train set shape:\", Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to visualize the digits.  No need to fully understand it\n",
    "# I just want to show you the data\n",
    "def visualize_digits(X, y, n_samples=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Visualize random digit samples from the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like of shape (n_samples, 64)\n",
    "        The digit image data (flattened 8x8 images)\n",
    "    y : array-like of shape (n_samples,)\n",
    "        The labels\n",
    "    n_samples : int\n",
    "        Number of samples to visualize\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Randomly select indices\n",
    "    indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "    \n",
    "    # Create subplot grid\n",
    "    n_cols = 5\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(2*n_cols, 2*n_rows))\n",
    "    \n",
    "    # Flatten axes for easier iteration\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Plot each digit\n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < n_samples:\n",
    "            # Reshape the flattened image back to 8x8\n",
    "            digit_image = X[indices[idx]].reshape(8, 8)\n",
    "            \n",
    "            # Plot the image\n",
    "            ax.imshow(digit_image, cmap='gray')\n",
    "            ax.set_title(f'Label: {y[indices[idx]]}')\n",
    "        \n",
    "        # Remove ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize 15 samples from X and corresponding label y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_digits(X, y, n_samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ML PPCA\n",
    "Compute ML estimates using spectral decomposition and project the data to a lower-dimensional space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## EM Algorithm Implementation for PPCA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code show example how to using standard PCA extract the latent embeddings and project the latent embeddings using t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def run_pca_once(X, n_comp):\n",
    "    \"\"\"\n",
    "    Run PCA once and return running time and results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    Z = pca.fit_transform(X)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, pca, Z\n",
    "\n",
    "def compare_svd_pca_components(X, y, components_list=[2, 5, 10, 20], n_runs=3):\n",
    "    \"\"\"\n",
    "    Compare PCA results with different numbers of components using SVD\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array-like\n",
    "        Input data\n",
    "    y : array-like\n",
    "        Labels for coloring\n",
    "    components_list : list\n",
    "        List of n_components to try\n",
    "    n_runs : int\n",
    "        Number of times to run each PCA for timing\n",
    "    \"\"\"\n",
    "    # Create subplot grid with 5 plots per row\n",
    "    n_plots = len(components_list)\n",
    "    n_cols = 5\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "    fig = plt.figure(figsize=(20, 4*n_rows))\n",
    "    gs = plt.GridSpec(n_rows, n_cols+1, width_ratios=[1]*n_cols + [0.05])\n",
    "    \n",
    "    # Initialize t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    \n",
    "    # Record running times\n",
    "    running_times = []\n",
    "    running_times_std = []  # Standard deviation of running times\n",
    "    #Record variance explained\n",
    "    var_explaineds = []\n",
    "    \n",
    "    # Create axes for plots\n",
    "    axes = []\n",
    "    for i in range(n_plots):\n",
    "        row = i // n_cols\n",
    "        col = i % n_cols\n",
    "        axes.append(plt.subplot(gs[row, col]))\n",
    "    \n",
    "    for idx, (ax, n_comp) in enumerate(zip(axes, components_list)):\n",
    "        # Run PCA multiple times\n",
    "        times = []\n",
    "        for _ in range(n_runs):\n",
    "            time_taken, pca, Z = run_pca_once(X, n_comp)\n",
    "            times.append(time_taken)\n",
    "        \n",
    "        # Calculate mean and std of running times\n",
    "        mean_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        running_times.append(mean_time)\n",
    "        running_times_std.append(std_time)\n",
    "        \n",
    "        # Use last PCA result for visualization\n",
    "        if n_comp > 2:\n",
    "            Z_2d = tsne.fit_transform(Z)\n",
    "        else:\n",
    "            Z_2d = Z\n",
    "            \n",
    "        # Plot\n",
    "        scatter = ax.scatter(Z_2d[:, 0], Z_2d[:, 1], c=y, cmap='tab10', s=10)\n",
    "        explained_var = np.sum(pca.explained_variance_ratio_) * 100\n",
    "        var_explaineds.append(explained_var)\n",
    "        ax.set_title(f'Standard-PCA (n={n_comp})\\nVar: {explained_var:.1f}%\\nTime: {mean_time:.3f}±{std_time:.3f}s')\n",
    "        ax.set_xlabel('Component 1')\n",
    "        ax.set_ylabel('Component 2')\n",
    "    \n",
    "    # Add colorbar in a separate axis\n",
    "    cbar_ax = plt.subplot(gs[:, -1])\n",
    "    plt.colorbar(scatter, cax=cbar_ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nDetailed results:\")\n",
    "    print(f\"{'n_components':<12} {'Time (s)':<15} {'Std Dev':<10} {'Variance Explained':<20}\")\n",
    "    print(\"-\" * 57)\n",
    "    for n_comp, mean_time, std_time, var_explained in zip(components_list, running_times, running_times_std, var_explaineds):\n",
    "\n",
    "        print(f\"{n_comp:<12} {mean_time:<15.3f} {std_time:<10.3f} {var_explained:<20.2f}%\")\n",
    "    \n",
    "    # Plot running times with error bars\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.errorbar(components_list, running_times, yerr=running_times_std, \n",
    "                fmt='o-', linewidth=2, markersize=8, capsize=5)\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Running Time (seconds)')\n",
    "    plt.title(f'PCA Running Time vs Number of Components\\n(Average of {n_runs} runs with std dev)')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "components_to_try = [2,  5,  7, 10, 13, 15, 17, 20, 30, 40,]\n",
    "compare_svd_pca_components(X, y, components_to_try, n_runs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML PPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following part, your just need to using your implementation of ML PPCA to extract the latent embedding Z in function `run_mlppca_once`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_mlppca_once(X, n_comp):\n    \"\"\"\n    Run ML-PPCA once and return running time and results\n    \n    Parameters:\n    -----------\n    X : array-like\n        Input data\n    n_comp : int\n        Number of components\n        \n    Returns:\n    --------\n    time_taken : float\n        Running time in seconds\n    Z : array-like\n        Transformed data\n    \"\"\"\n    start_time = time.time()\n    # write your code here to get the latent embeddings Z using your own implementation of ML-PPCA\n    # some code here\n    # Z=\n    end_time = time.time()\n    return end_time - start_time, Z\n\ndef compare_mlpca_components(X, y, components_list=[2, 5, 10, 20], n_runs=3):\n    \"\"\"\n    Compare ML-PPCA results with different numbers of components\n    \n    Parameters:\n    -----------\n    X : array-like\n        Input data\n    y : array-like\n        Labels for coloring\n    components_list : list\n        List of n_components to try\n    n_runs : int\n        Number of times to run each PPCA for timing\n    \"\"\"\n    # Create subplot grid with 5 plots per row\n    n_plots = len(components_list)\n    n_cols = 5\n    n_rows = (n_plots + n_cols - 1) // n_cols\n    fig = plt.figure(figsize=(20, 4*n_rows))\n    gs = plt.GridSpec(n_rows, n_cols+1, width_ratios=[1]*n_cols + [0.05])\n    \n    # Initialize t-SNE\n    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n    \n    # Record running times\n    running_times = []\n    running_times_std = []  # Standard deviation of running times\n    \n    # Create axes for plots\n    axes = []\n    for i in range(n_plots):\n        row = i // n_cols\n        col = i % n_cols\n        axes.append(plt.subplot(gs[row, col]))\n    \n    for idx, (ax, n_comp) in enumerate(zip(axes, components_list)):\n        # Run ML-PPCA multiple times\n        times = []\n        for _ in range(n_runs):\n            time_taken, Z = run_mlppca_once(X, n_comp)\n            times.append(time_taken)\n        \n        # Calculate mean and std of running times\n        mean_time = np.mean(times)\n        std_time = np.std(times)\n        running_times.append(mean_time)\n        running_times_std.append(std_time)\n        \n        # Use last PPCA result for visualization\n        if n_comp > 2:\n            Z_2d = tsne.fit_transform(Z)\n        else:\n            Z_2d = Z\n            \n        # Plot\n        scatter = ax.scatter(Z_2d[:, 0], Z_2d[:, 1], c=y, cmap='tab10', s=10)\n        ax.set_title(f'ML-PPCA (n={n_comp})\\nTime: {mean_time:.3f}±{std_time:.3f}s')\n        ax.set_xlabel('Component 1')\n        ax.set_ylabel('Component 2')\n    \n    # Add colorbar in a separate axis\n    cbar_ax = plt.subplot(gs[:, -1])\n    plt.colorbar(scatter, cax=cbar_ax)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Print detailed results\n    print(\"\\nDetailed results:\")\n    print(f\"{'n_components':<12} {'Time (s)':<15} {'Std Dev':<10}\")\n    print(\"-\" * 37)\n    for n_comp, mean_time, std_time in zip(components_list, running_times, running_times_std):\n        print(f\"{n_comp:<12} {mean_time:<15.3f} {std_time:<10.3f}\")\n    \n    # Plot running times with error bars\n    plt.figure(figsize=(10, 5))\n    plt.errorbar(components_list, running_times, yerr=running_times_std, \n                fmt='o-', linewidth=2, markersize=8, capsize=5)\n    plt.xlabel('Number of Components')\n    plt.ylabel('Running Time (seconds)')\n    plt.title(f'ML-PPCA Running Time vs Number of Components\\n(Average of {n_runs} runs with std dev)')\n    plt.grid(True)\n    plt.show()\n\ncomponents_to_try = [2, 5, 7, 10, 13, 15, 17, 20, 30, 40]\n# set n_runs to 1 for debugging; set n_runs to 3 for final submission\ncompare_mlpca_components(X, y, components_to_try, n_runs=1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM PPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, you just need to use your implement of EM PPCA to extract the latent embedding Z and record the log-likelihood values during iterations in function `run_ppca_em_once`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_ppca_em_once(X, n_comp, n_iter=30, seed=None):\n    \"\"\"\n    Run PPCA EM algorithm once and return running time and results\n    \n    Parameters:\n    -----------\n    X : array-like\n        Input data\n    n_comp : int\n        Number of components\n    n_iter : int\n        Number of EM iterations\n    seed : int\n        Random seed for initialization\n        \n    Returns:\n    --------\n    time_taken : float\n        Running time in seconds\n    Z : array-like\n        Transformed data\n    Q_history : list\n        History of log-likelihood values\n    \"\"\"\n    start_time = time.time()\n    \n    # Initialize PPCA and Run EM iterations\n    # some code here\n    # Z=\n    # Q_history=\n    \n\n    \n    end_time = time.time()\n    return end_time - start_time, Z, Q_history\n\ndef compare_ppca_em_components(X, y, components_list=[2, 5, 10, 20], n_runs=3, n_iter=30):\n    \"\"\"\n    Compare PPCA EM results with different numbers of components\n    \n    Parameters:\n    -----------\n    X : array-like\n        Input data\n    y : array-like\n        Labels for coloring\n    components_list : list\n        List of n_components to try\n    n_runs : int\n        Number of times to run each PPCA for timing\n    n_iter : int\n        Maximum number of EM iterations\n    \"\"\"\n    # Create subplot grid with 5 plots per row\n    n_plots = len(components_list)\n    n_cols = 5\n    n_rows = (n_plots + n_cols - 1) // n_cols\n    fig = plt.figure(figsize=(20, 4*n_rows))\n    gs = plt.GridSpec(n_rows, n_cols+1, width_ratios=[1]*n_cols + [0.05])\n    \n    # Initialize t-SNE\n    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n    \n    # Record running times and convergence iterations\n    running_times = []\n    running_times_std = []\n    convergence_iters = []\n    convergence_iters_std = []\n    \n    # Create axes for plots\n    axes = []\n    for i in range(n_plots):\n        row = i // n_cols\n        col = i % n_cols\n        axes.append(plt.subplot(gs[row, col]))\n    \n    for idx, (ax, n_comp) in enumerate(zip(axes, components_list)):\n        # Run PPCA EM multiple times\n        times = []\n        iters = []\n        for run in range(n_runs):\n            time_taken, Z, Q_history = run_ppca_em_once(X, n_comp, n_iter, seed=42+run)\n            times.append(time_taken)\n            iters.append(len(Q_history)-1)  # -1 because Q_history includes initial value\n        \n        # Calculate statistics\n        mean_time = np.mean(times)\n        std_time = np.std(times)\n        mean_iters = np.mean(iters)\n        std_iters = np.std(iters)\n        \n        running_times.append(mean_time)\n        running_times_std.append(std_time)\n        convergence_iters.append(mean_iters)\n        convergence_iters_std.append(std_iters)\n        \n        # Use last PPCA result for visualization\n        if n_comp > 2:\n            Z_2d = tsne.fit_transform(Z)\n        else:\n            Z_2d = Z\n            \n        # Plot\n        scatter = ax.scatter(Z_2d[:, 0], Z_2d[:, 1], c=y, cmap='tab10', s=10)\n        ax.set_title(f'PPCA EM (n={n_comp})\\nTime: {mean_time:.3f}±{std_time:.3f}s\\nIters: {mean_iters:.1f}±{std_iters:.1f}')\n        ax.set_xlabel('Component 1')\n        ax.set_ylabel('Component 2')\n    \n    # Add colorbar in a separate axis\n    cbar_ax = plt.subplot(gs[:, -1])\n    plt.colorbar(scatter, cax=cbar_ax)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Print detailed results\n    print(\"\\nDetailed results:\")\n    print(f\"{'n_components':<12} {'Time (s)':<15} {'Std Dev':<10} {'Iterations':<15} {'Iter Std Dev':<10}\")\n    print(\"-\" * 62)\n    for n_comp, mean_time, std_time, mean_iter, std_iter in zip(\n        components_list, running_times, running_times_std, convergence_iters, convergence_iters_std):\n        print(f\"{n_comp:<12} {mean_time:<15.3f} {std_time:<10.3f} {mean_iter:<15.1f} {std_iter:<10.1f}\")\n    \n    # Plot running times with error bars\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # Time plot\n    ax1.errorbar(components_list, running_times, yerr=running_times_std, \n                fmt='o-', linewidth=2, markersize=8, capsize=5)\n    ax1.set_xlabel('Number of Components')\n    ax1.set_ylabel('Running Time (seconds)')\n    ax1.set_title(f'PPCA EM Running Time\\n(Average of {n_runs} runs with std dev)')\n    ax1.grid(True)\n    \n    # Iterations plot\n    ax2.errorbar(components_list, convergence_iters, yerr=convergence_iters_std,\n                fmt='o-', linewidth=2, markersize=8, capsize=5)\n    ax2.set_xlabel('Number of Components')\n    ax2.set_ylabel('Number of Iterations')\n    ax2.set_title(f'PPCA EM Convergence Iterations\\n(Average of {n_runs} runs with std dev)')\n    ax2.grid(True)\n    \n    plt.tight_layout()\n    plt.show()\n\n\ncomponents_to_try = [2, 5, 7, 10, 13, 15, 17, 20, 30, 40]\n# set n_runs to 1 for debugging; set n_runs to 3 for final submission\ncompare_ppca_em_components(X, y, components_to_try, n_runs=1, n_iter=50)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}